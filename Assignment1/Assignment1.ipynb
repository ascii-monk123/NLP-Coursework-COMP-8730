{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05264d28",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65aa3c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytrec_eval in /Users/dawarwaqar/anaconda3/lib/python3.11/site-packages (0.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytrec_eval\n",
    "from main import preprocess_corpus, reduce_spelling_errors_corpus_length, calculate_med, get_top_k_words, s_at_K_for_every_incorrect_token, compute_avg_at_K\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9554cb",
   "metadata": {},
   "source": [
    "# Function to pre-process the spelling error corpus\n",
    "- Corpus Name: Birbeck Corpus\n",
    "-  Retrieved from: https://www.dcs.bbk.ac.uk/~ROGER/corpora.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde39e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of misspelled words : 36133\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_corpus('./missp.dat.txt')\n",
    "\n",
    "print('Total number of misspelled words : {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb5364",
   "metadata": {},
   "source": [
    "# Change misspelled corpus length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566cb89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557\n"
     ]
    }
   ],
   "source": [
    "df = reduce_spelling_errors_corpus_length(df, 600)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba40257",
   "metadata": {},
   "source": [
    "# Comparison of our Minimum Edit Distance (MED) function with the inbuilt nltk function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc92a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "8\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import distance\n",
    "\n",
    "def med_nltk(str1:str, str2:str)->int:\n",
    "  return distance.edit_distance(str1, str2, substitution_cost=2, transpositions=False)\n",
    "\n",
    "print(calculate_med(\"hello\", \"hell\"))\n",
    "print(med_nltk(\"hello\", \"hell\"))\n",
    "print(calculate_med(\"random\", \"randomizer\"))\n",
    "print(med_nltk(\"random\", \"randomizer\"))\n",
    "print(calculate_med(\"saiyan\", \"senorita\"))\n",
    "print(med_nltk(\"saiyan\", \"senorita\"))\n",
    "print(calculate_med(\"des\", \"\"))\n",
    "print(med_nltk(\"des\", \"\"))\n",
    "print(calculate_med(\"\", \"asa\"))\n",
    "print(med_nltk(\"\", \"asa\"))\n",
    "print(calculate_med(\"\", \"\"))\n",
    "print(med_nltk(\"\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91970bbc",
   "metadata": {},
   "source": [
    "Seems like our method is working perfectly in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3bcc4",
   "metadata": {},
   "source": [
    "# Getting the top K words for the first 15 misspelled tokens\n",
    "Top k words are the number of words which have the least distance according to the Minimum Edit Distance(M.E.D) algorithm. The incorrect words are compared to all the words in the wordnet dictionary. In our assignment the k values are k = {1, 5, 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c63d8",
   "metadata": {},
   "source": [
    "## Case 1: No parallelization present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05136085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 42.91403007507324\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results = []\n",
    "\n",
    "for row in df[:15]:\n",
    "  results.append(get_top_k_words(row))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"time taken: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa1eb9",
   "metadata": {},
   "source": [
    "## Case 2: With Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfadc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 12.537324666976929\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    results = []\n",
    "    start = time.time()\n",
    "    with mp.Pool(processes=16) as p:\n",
    "        results = p.map(get_top_k_words, df[:15])\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"time taken: {end - start}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614fb42c",
   "metadata": {},
   "source": [
    "# Getting the top K words for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf41b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dawarwaqar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 311.5308048725128\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    results = []\n",
    "    start = time.time()\n",
    "    with mp.Pool(processes=16) as p:\n",
    "        results = p.map(get_top_k_words, df)\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    with open('final_results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    \n",
    "    print(f\"time taken: {end - start}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbf6b3",
   "metadata": {},
   "source": [
    "# Calculating S@K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98599fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open('final_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "s_at_K = s_at_K_for_every_incorrect_token(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66355d6",
   "metadata": {},
   "source": [
    "# Calculating Average Success at K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77708218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s@1': 0.2911392405063291, 's@5': 0.4484629294755877, 's@10': 0.5135623869801085}\n"
     ]
    }
   ],
   "source": [
    "avg_succ_at_K = compute_avg_at_K(s_at_K)\n",
    "print(avg_succ_at_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e05bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
